# Responsible AI on Microsoft Azure

### Responsible AI Practices

Building responsible artificial intelligence platforms requires following a pattern that involves asking teams to Identify, Measure, and Mitigate potential harms, and have a plan for how to Operate the AI system as well. In alignment with those practices, these recommendations are organized into the following four stages:

- **Identify**: Identify and prioritize potential harms that could result from your AI system through iterative red-teaming, stress-testing, and analysis.
- **Measure**: Measure the frequency and severity of those harms by establishing clear metrics, creating measurement test sets, and completing iterative, systematic testing (both manual and automated).
- **Mitigate**: Mitigate harms by implementing tools and strategies such as prompt engineering and using our content filters. Repeat measurement to test effectiveness after implementing mitigations.
- **Operate**: Define and execute a deployment and operational readiness plan.

### References
- https://www.microsoft.com/en-us/ai/responsible-ai
- https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2
